{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "598ab4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data=pd.read_excel('Bats_Data.xlsx', index_col=0) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c21bebe",
   "metadata": {},
   "source": [
    "# Co-occurrence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4f26f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_cooccurence(i,j,dataframe):\n",
    "    res=0\n",
    "    for k in range(0,len(dataframe)-1):\n",
    "        val1=list(dataframe.iloc[k])[7+i]\n",
    "        val2=list(dataframe.iloc[k])[7+j]\n",
    "        \n",
    "        if (val1 != 0) and (val2 !=0):\n",
    "            res=1\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c68bd61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temporal Diversity:  0.5639722958288795\n",
      "Temporal variation of species:  0.46385395848851696\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data=pd.read_excel('data1.xlsx', index_col=0)\n",
    "years=[2011,2012,2013,2014]\n",
    "#years=[2011]\n",
    "#hab='1_ha fragment_interior'\n",
    "#hab='10_ha fragment_interior'\n",
    "#hab='100_ha fragment_interior'\n",
    "hab='NA continuous_forest'\n",
    "list_species=list(data.head(1))[7:48]\n",
    "\n",
    "\n",
    "d_species_prop=dict()  # dict(species:{t1: p1, t2: p2 ......})\n",
    "for i in list_species:\n",
    "    d_species_prop[i]=dict()\n",
    "    for j in years:\n",
    "        d_species_prop[i][j]=0\n",
    "\n",
    "\n",
    "dict_strength_connectivity2=dict()\n",
    "for i in list_species:\n",
    "    dict_strength_connectivity2[i]=dict()\n",
    "    for j in years:\n",
    "        dict_strength_connectivity2[i][j]=0\n",
    "        \n",
    "for year in years:\n",
    "    if year==2011:\n",
    "        d2=data.loc[(data['date'] > '2011-01-01') & (data['date'] < '2011-12-31') & (data['Hab'] == hab)]\n",
    "    if year==2012:\n",
    "        d2=data.loc[(data['date'] > '2012-01-01') & (data['date'] < '2012-12-31') & (data['Hab'] == hab)]\n",
    "    if year==2013:\n",
    "        d2=data.loc[(data['date'] > '2013-01-01') & (data['date'] < '2013-12-31') & (data['Hab'] == hab)]\n",
    "    if year==2014:\n",
    "        d2=data.loc[(data['date'] > '2014-01-01') & (data['date'] < '2014-12-31') & (data['Hab'] == hab)]\n",
    "    \n",
    "    nbr_samples=len(d2)-1\n",
    "\n",
    "\n",
    "    #for sample_position in range(0,191):\n",
    "    #    sample=list(data.iloc[sample_position])\n",
    "    #    if (sample[6]==season && sample.year==year):\n",
    "        \n",
    "        \n",
    "    list_edges=list()\n",
    "        \n",
    "    for i in range(0,len(list_species)):\n",
    "        j=i+1\n",
    "        while j<len(list_species):\n",
    "            sp1=list_species[i]\n",
    "            sp2=list_species[j]\n",
    "        \n",
    "            somme_sp1=sum(list(d2[sp1]))\n",
    "            somme_sp2=sum(list(d2[sp2]))\n",
    "            tot=somme_sp1+somme_sp2\n",
    "        \n",
    "            s=0\n",
    "            for k in range(0,nbr_samples):\n",
    "                s=s+abs(list(d2[sp1])[k]-list(d2[sp2])[k])\n",
    "        \n",
    "            if tot==0:\n",
    "                weight=1\n",
    "            else:\n",
    "                weight=1-(s/tot)\n",
    "            \n",
    "            res=0\n",
    "            res=verify_cooccurence(i,j,d2)\n",
    "            \n",
    "            if res == 1:\n",
    "                list_edges.append((sp1,sp2,weight))\n",
    "        \n",
    "            j=j+1\n",
    "        \n",
    "     \n",
    "    #print(list_edges)        \n",
    "    g = nx.Graph()  \n",
    "    g.add_weighted_edges_from(list_edges)\n",
    "    #print(list(g.edges(data=True)))\n",
    "\n",
    "    #if nx.is_empty(g)==False:\n",
    "    #    dict_size[index_gsa].append(len(g))\n",
    "    #    dict_edges[index_gsa].append(len(list(g.edges())))    \n",
    "    #    dict_density[index_gsa].append(nx.density(g))\n",
    "    #    dict_transitivity[index_gsa].append(nx.transitivity(g))\n",
    "    #    dict_assortativity[index_gsa].append(nx.degree_assortativity_coefficient(g))\n",
    "    #    dict_diameter[index_gsa].append(nx.diameter(g))\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "    dict_strength=dict() # node/specie: strength\n",
    "    l_strg=list()\n",
    "    for node in g:\n",
    "        s=0\n",
    "        l=g.edges(node, data=True)\n",
    "        for e in l:\n",
    "            s=s+e[2]['weight']\n",
    "        dict_strength[node]=s\n",
    "        l_strg.append(s)\n",
    "         \n",
    "    for node in g:\n",
    "        dict_strength[node]=dict_strength[node]/max(l_strg)\n",
    "    #print() \n",
    "    #print(dict_strength)\n",
    "            \n",
    "        \n",
    "    dict_degree=nx.degree_centrality(g) # node/specie: degree\n",
    "    #print()\n",
    "    #print(dict_degree)\n",
    "        \n",
    "    dict_strength_connectivity=dict()   # node/specie: strength connectivity\n",
    "        \n",
    "    for i in dict_strength:\n",
    "        dict_strength_connectivity[i]=math.sqrt(dict_strength[i]*dict_strength[i]+dict_degree[i]*dict_degree[i])\n",
    "        dict_strength_connectivity2[i][year]=dict_strength_connectivity[i]\n",
    "    #print()\n",
    "    #print(dict_strength_connectivity)\n",
    "    \n",
    "    ptot=sum(list(dict_strength_connectivity.values()))\n",
    "            \n",
    "    for i in dict_strength_connectivity:\n",
    "        if ptot==0:\n",
    "            dict_strength_connectivity[i]=0\n",
    "        else:\n",
    "            dict_strength_connectivity[i]=dict_strength_connectivity[i]/ptot\n",
    "        \n",
    "        d_species_prop[i][year]=dict_strength_connectivity[i]\n",
    "    #print()\n",
    "    #print(dict_strength_connectivity)\n",
    "    #print()\n",
    "    #print(d_species_prop)  \n",
    "    \n",
    "    \n",
    "    #width_o=15\n",
    "    #hight_o=15\n",
    "    #plt.subplots_adjust(left = 0.01, bottom = 0.01, right = 0.99, top = 0.99)\n",
    "    #plt.figure(figsize=(width_o,hight_o))  # image is 8 x 8 inches\n",
    "    #plt.axis('off')\n",
    "    #nx.draw_networkx(g, with_labels=True, node_size=[v * 20000 for v in dict_strength_connectivity.values()] ,node_color=[\"#90EE90\"], font_size=12, font_color='k', font_family='sans-serif', font_weight='bold')\n",
    "    #plt.savefig('bats.jpg',dpi=300)\n",
    "            \n",
    "# computing temporal diversity            \n",
    "s=0\n",
    "for i in list_species:\n",
    "    list_of_proportion=list(d_species_prop[i].values())\n",
    "    set_of_proportion=set(list_of_proportion)\n",
    "    #print(set_of_proportion)\n",
    "    \n",
    "    for j in set_of_proportion:\n",
    "        if j!=0:\n",
    "            s=s-((list_of_proportion.count(j)/4)*j*math.log(j))\n",
    "    \n",
    "s=math.exp(s)\n",
    "    \n",
    "#print(s)\n",
    "print('Temporal Diversity: ',(s-1)/(40))\n",
    "#print(d_species_prop)\n",
    "\n",
    "\n",
    "\n",
    "# computing temporal variation of species    \n",
    "#print(dict_strength_connectivity2)\n",
    "for i in dict_strength_connectivity2:\n",
    "    ptot=sum(list(dict_strength_connectivity2[i].values()))\n",
    "    for j in dict_strength_connectivity2[i]:\n",
    "        if ptot==0:\n",
    "            dict_strength_connectivity2[i][j]=0\n",
    "        else:\n",
    "            dict_strength_connectivity2[i][j]=dict_strength_connectivity2[i][j]/ptot\n",
    "#print(dict_strength_connectivity2)    \n",
    "\n",
    "\n",
    "b=dict()  \n",
    "for i in list_species:\n",
    "    b[i]=0\n",
    "    for j in dict_strength_connectivity2[i]:\n",
    "        if dict_strength_connectivity2[i][j]!=0:\n",
    "            b[i]=b[i]-dict_strength_connectivity2[i][j]*math.log(dict_strength_connectivity2[i][j])\n",
    "    b[i]=math.exp(b[i])\n",
    "    \n",
    "btot=sum(list(b.values()))\n",
    "print('Temporal variation of species: ',1-((btot-41)/(41*3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed0dc46f",
   "metadata": {},
   "source": [
    "# Co-occurrence & functional distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "334d09dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temporal Diversity:  0.20650412814186772\n",
      "Temporal variation of species:  0.8504786336962136\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "\n",
    "data_fct=pd.read_excel('gower.xlsx', index_col=0)\n",
    "data=pd.read_excel('data1.xlsx', index_col=0)\n",
    "years=[2011,2012,2013,2014]\n",
    "#years=[2011]\n",
    "hab='1_ha fragment_interior'\n",
    "#hab='10_ha fragment_interior'\n",
    "#hab='100_ha fragment_interior'\n",
    "#hab='NA continuous_forest'\n",
    "list_species=list(data.head(1))[7:48]\n",
    "\n",
    "\n",
    "d_species_prop=dict()  # dict(species:{t1: p1, t2: p2 ......})\n",
    "for i in list_species:\n",
    "    d_species_prop[i]=dict()\n",
    "    for j in years:\n",
    "        d_species_prop[i][j]=0\n",
    "\n",
    "\n",
    "dict_strength_connectivity2=dict()\n",
    "for i in list_species:\n",
    "    dict_strength_connectivity2[i]=dict()\n",
    "    for j in years:\n",
    "        dict_strength_connectivity2[i][j]=0\n",
    "        \n",
    "for year in years:\n",
    "    if year==2011:\n",
    "        d2=data.loc[(data['date'] > '2011-01-01') & (data['date'] < '2011-12-31') & (data['Hab'] == hab)]\n",
    "    if year==2012:\n",
    "        d2=data.loc[(data['date'] > '2012-01-01') & (data['date'] < '2012-12-31') & (data['Hab'] == hab)]\n",
    "    if year==2013:\n",
    "        d2=data.loc[(data['date'] > '2013-01-01') & (data['date'] < '2013-12-31') & (data['Hab'] == hab)]\n",
    "    if year==2014:\n",
    "        d2=data.loc[(data['date'] > '2014-01-01') & (data['date'] < '2014-12-31') & (data['Hab'] == hab)]\n",
    "    \n",
    "    nbr_samples=len(d2)-1\n",
    "\n",
    "\n",
    "    #for sample_position in range(0,191):\n",
    "    #    sample=list(data.iloc[sample_position])\n",
    "    #    if (sample[6]==season && sample.year==year):\n",
    "        \n",
    "        \n",
    "    list_edges=list()\n",
    "        \n",
    "    for i in range(0,len(list_species)):\n",
    "        j=i+1\n",
    "        while j<len(list_species):\n",
    "            sp1=list_species[i]\n",
    "            sp2=list_species[j]\n",
    "        \n",
    "            somme_sp1=sum(list(d2[sp1]))\n",
    "            somme_sp2=sum(list(d2[sp2]))\n",
    "            tot=somme_sp1+somme_sp2\n",
    "        \n",
    "            s=0\n",
    "            for k in range(0,nbr_samples):\n",
    "                s=s+abs(list(d2[sp1])[k]-list(d2[sp2])[k])\n",
    "        \n",
    "            if tot==0:\n",
    "                weight=1\n",
    "            else:\n",
    "                weight=1-(s/tot)\n",
    "                \n",
    "            weight=weight*data_fct.loc[sp1].at[sp2]\n",
    "            \n",
    "            res=0\n",
    "            res=verify_cooccurence(i,j,d2)\n",
    "            \n",
    "            if res == 1:\n",
    "                list_edges.append((sp1,sp2,weight))\n",
    "        \n",
    "            j=j+1\n",
    "        \n",
    "     \n",
    "    #print(list_edges)        \n",
    "    g = nx.Graph()  \n",
    "    g.add_weighted_edges_from(list_edges)\n",
    "    #print(list(g.edges(data=True)))\n",
    "\n",
    "    #if nx.is_empty(g)==False:\n",
    "    #    dict_size[index_gsa].append(len(g))\n",
    "    #    dict_edges[index_gsa].append(len(list(g.edges())))    \n",
    "    #    dict_density[index_gsa].append(nx.density(g))\n",
    "    #    dict_transitivity[index_gsa].append(nx.transitivity(g))\n",
    "    #    dict_assortativity[index_gsa].append(nx.degree_assortativity_coefficient(g))\n",
    "    #    dict_diameter[index_gsa].append(nx.diameter(g))\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "    dict_strength=dict() # node/specie: strength\n",
    "    l_strg=list()\n",
    "    for node in g:\n",
    "        s=0\n",
    "        l=g.edges(node, data=True)\n",
    "        for e in l:\n",
    "            s=s+e[2]['weight']\n",
    "        dict_strength[node]=s\n",
    "        l_strg.append(s)\n",
    "         \n",
    "    for node in g:\n",
    "        dict_strength[node]=dict_strength[node]/max(l_strg)\n",
    "    #print() \n",
    "    #print(dict_strength)\n",
    "            \n",
    "        \n",
    "    dict_degree=nx.degree_centrality(g) # node/specie: degree\n",
    "    #print()\n",
    "    #print(dict_degree)\n",
    "        \n",
    "    dict_strength_connectivity=dict()   # node/specie: strength connectivity\n",
    "        \n",
    "    for i in dict_strength:\n",
    "        dict_strength_connectivity[i]=math.sqrt(dict_strength[i]*dict_strength[i]+dict_degree[i]*dict_degree[i])\n",
    "        dict_strength_connectivity2[i][year]=dict_strength_connectivity[i]\n",
    "    #print()\n",
    "    #print(dict_strength_connectivity)\n",
    "    \n",
    "    ptot=sum(list(dict_strength_connectivity.values()))\n",
    "            \n",
    "    for i in dict_strength_connectivity:\n",
    "        if ptot==0:\n",
    "            dict_strength_connectivity[i]=0\n",
    "        else:\n",
    "            dict_strength_connectivity[i]=dict_strength_connectivity[i]/ptot\n",
    "        \n",
    "        d_species_prop[i][year]=dict_strength_connectivity[i]\n",
    "    #print()\n",
    "    #print(dict_strength_connectivity)\n",
    "    #print()\n",
    "    #print(d_species_prop)  \n",
    "            \n",
    "# computing temporal diversity            \n",
    "s=0\n",
    "for i in list_species:\n",
    "    list_of_proportion=list(d_species_prop[i].values())\n",
    "    set_of_proportion=set(list_of_proportion)\n",
    "    #print(set_of_proportion)\n",
    "    \n",
    "    for j in set_of_proportion:\n",
    "        if j!=0:\n",
    "            s=s-((list_of_proportion.count(j)/4)*j*math.log(j))\n",
    "    \n",
    "s=math.exp(s)\n",
    "    \n",
    "#print(s)\n",
    "print('Temporal Diversity: ',(s-1)/(40))\n",
    "#print(d_species_prop)\n",
    "\n",
    "\n",
    "\n",
    "# computing temporal variation of species    \n",
    "#print(dict_strength_connectivity2)\n",
    "for i in dict_strength_connectivity2:\n",
    "    ptot=sum(list(dict_strength_connectivity2[i].values()))\n",
    "    for j in dict_strength_connectivity2[i]:\n",
    "        if ptot==0:\n",
    "            dict_strength_connectivity2[i][j]=0\n",
    "        else:\n",
    "            dict_strength_connectivity2[i][j]=dict_strength_connectivity2[i][j]/ptot\n",
    "#print(dict_strength_connectivity2)    \n",
    "\n",
    "\n",
    "b=dict()  \n",
    "for i in list_species:\n",
    "    b[i]=0\n",
    "    for j in dict_strength_connectivity2[i]:\n",
    "        if dict_strength_connectivity2[i][j]!=0:\n",
    "            b[i]=b[i]-dict_strength_connectivity2[i][j]*math.log(dict_strength_connectivity2[i][j])\n",
    "    b[i]=math.exp(b[i])\n",
    "    \n",
    "btot=sum(list(b.values()))\n",
    "print('Temporal variation of species: ',1-((btot-41)/(41*3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c2a3a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
